{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We will be using the Drug Review Dataset (Drugs.com) for this workshop.\n",
    "\n",
    "Felix Gräßer, Surya Kallumadi, Hagen Malberg, and Sebastian Zaunseder. 2018. Aspect-Based Sentiment Analysis of Drug Reviews Applying Cross-Domain and Cross-Data Learning. In Proceedings of the 2018 International Conference on Digital Health (DH '18). ACM, New York, NY, USA, 121-125. DOI: [https://dl.acm.org/citation.cfm?doid=3194658.3194677]\n",
    "\n",
    "It is a part of the UCI machine learning repository.\n",
    "\n",
    "Dua, D. and Graff, C. (2019). [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session=sagemaker.Session()\n",
    "sagemaker_bucket = sagemaker_session.default_bucket()\n",
    "bucket_name = 'lfs401-2019reinvent-public-cmh'\n",
    "source_key = 'drugsCom_raw.tsv'\n",
    "role = get_execution_role()\n",
    "\n",
    "source_prefix = 'source' \n",
    "reviews_data_prefix = 'reviews'\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, let's explore the source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drugsCom_raw.tsv, size = 107.16MB\n"
     ]
    }
   ],
   "source": [
    "def file_size(size):\n",
    "    splitter = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]\n",
    "    splitter_index = 0\n",
    "    while size > 1024 and splitter_index < 5:\n",
    "        splitter_index += 1\n",
    "        size = size/1024\n",
    "    size = '{:0.2f}'.format(size)\n",
    "    return '{}{}'.format(size,splitter[splitter_index])\n",
    "\n",
    "obj = s3.Object(bucket_name=bucket_name, key=source_prefix + '/' + source_key)\n",
    "obj_summary = s3.ObjectSummary(bucket_name=bucket_name, key=source_prefix + '/' + source_key)\n",
    "\n",
    "print(obj.key.split('/')[-1] +', size = '+ file_size(obj_summary.size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_file(file_name, prefix, index_col=None, usecols=None, parse_dates=None):\n",
    "    response = s3_client.get_object(Bucket=bucket_name, Key=prefix+'/'+file_name)\n",
    "    response_body = response[\"Body\"].read()\n",
    "    return pd.read_csv(io.BytesIO(response_body), header=0, delimiter=\"\\t\", low_memory=False,\n",
    "                      index_col=index_col, usecols=usecols, error_bad_lines=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drugsCom_raw.tsv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>May 20, 2012</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>April 27, 2010</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>December 14, 2009</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138000</td>\n",
       "      <td>Ortho Evra</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"This is my first time using any form of birth...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>November 3, 2015</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35696</td>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>November 27, 2016</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  drugName                     condition  \\\n",
       "0      206461                 Valsartan  Left Ventricular Dysfunction   \n",
       "1       95260                Guanfacine                          ADHD   \n",
       "2       92703                    Lybrel                 Birth Control   \n",
       "3      138000                Ortho Evra                 Birth Control   \n",
       "4       35696  Buprenorphine / naloxone             Opiate Dependence   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  \"It has no side effect, I take it in combinati...     9.0   \n",
       "1  \"My son is halfway through his fourth week of ...     8.0   \n",
       "2  \"I used to take another oral contraceptive, wh...     5.0   \n",
       "3  \"This is my first time using any form of birth...     8.0   \n",
       "4  \"Suboxone has completely turned my life around...     9.0   \n",
       "\n",
       "                date  usefulCount  \n",
       "0       May 20, 2012           27  \n",
       "1     April 27, 2010          192  \n",
       "2  December 14, 2009           17  \n",
       "3   November 3, 2015           10  \n",
       "4  November 27, 2016           37  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note = source_key\n",
    "print (note)\n",
    "notes_partial = load_data_file(note, source_prefix)\n",
    "notes_partial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215063, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_partial.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this demo, we will subselect 50 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_50 = notes_partial.sample(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70062</th>\n",
       "      <td>157081</td>\n",
       "      <td>Differin</td>\n",
       "      <td>Acne</td>\n",
       "      <td>\"Patience, patience, patience! I have been usi...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>July 9, 2017</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202980</th>\n",
       "      <td>193764</td>\n",
       "      <td>Hydrocodone</td>\n",
       "      <td>Pain</td>\n",
       "      <td>\"My doc switched me to this due to some issues...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>September 28, 2017</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173276</th>\n",
       "      <td>5279</td>\n",
       "      <td>Zonisamide</td>\n",
       "      <td>Migraine Prevention</td>\n",
       "      <td>\"I took 300mg of zonegran for nearly 2 years. ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>March 18, 2016</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95297</th>\n",
       "      <td>100734</td>\n",
       "      <td>Orlistat</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>\"I used alli because I wanted to lose weight b...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>November 7, 2016</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143571</th>\n",
       "      <td>20425</td>\n",
       "      <td>Vimpat</td>\n",
       "      <td>Seizures</td>\n",
       "      <td>\"I&amp;#039;m 25 and a little over 1 year ago I ha...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>October 23, 2015</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0     drugName            condition  \\\n",
       "70062       157081     Differin                 Acne   \n",
       "202980      193764  Hydrocodone                 Pain   \n",
       "173276        5279   Zonisamide  Migraine Prevention   \n",
       "95297       100734     Orlistat              Obesity   \n",
       "143571       20425       Vimpat             Seizures   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "70062   \"Patience, patience, patience! I have been usi...    10.0   \n",
       "202980  \"My doc switched me to this due to some issues...     4.0   \n",
       "173276  \"I took 300mg of zonegran for nearly 2 years. ...     7.0   \n",
       "95297   \"I used alli because I wanted to lose weight b...    10.0   \n",
       "143571  \"I&#039;m 25 and a little over 1 year ago I ha...     5.0   \n",
       "\n",
       "                      date  usefulCount  \n",
       "70062         July 9, 2017           45  \n",
       "202980  September 28, 2017           15  \n",
       "173276      March 18, 2016           36  \n",
       "95297     November 7, 2016           80  \n",
       "143571    October 23, 2015           18  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_50.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, pick the number of topics to use\n",
    "\n",
    "Now that we have loaded the file, we will pick the number of topics to use. This has three steps:\n",
    "1. Use Amazon Comprehend Medical to identify topics in each review.\n",
    "2. Plot the distribution of the number of topics\n",
    "3. Randomly select the topics from each column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Identify topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_cnt = 1\n",
    "cm = boto3.client('comprehendmedical')\n",
    "\n",
    "topics_per_row = list()\n",
    "\n",
    "for index,row in notes_50.iterrows():\n",
    "    topic_list = []\n",
    "    \n",
    "    # For each row, use Comprehend Medical to detect entitites\n",
    "    entities = cm.detect_entities(Text=row['review'])\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Filter by Medical Condition\n",
    "    for entity in entities['Entities']:\n",
    "        if entity['Category'] == 'MEDICAL_CONDITION':\n",
    "            topic_list.append(entity['Text'])\n",
    "            topic_cnt += 1\n",
    "    topic_dict=dict(\n",
    "        Index=index,\n",
    "        DrugName=row['drugName'],\n",
    "        TopicList=topic_list\n",
    "    )\n",
    "    topics_per_row.append(topic_dict)\n",
    "    print (index)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_per_row[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Plot topic distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_count = [ len(_['TopicList']) for _ in topics_per_row]\n",
    "plt.hist(topic_count,bins=20,label='Topic Count')\n",
    "plt.xlabel('Number of topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Create topic list and review the output. In this example, we only use reviews with at least 5 germane topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=pd.DataFrame(columns=['drugName','topic1','topic2','topic3','topic4','topic5'])\n",
    "min_topic_len = 5\n",
    "\n",
    "for row in topics_per_row:\n",
    "    topic_list = row['TopicList']\n",
    "    if len(topic_list) >= min_topic_len:\n",
    "        # Randomly select topics\n",
    "        random_topics = random.choices(topic_list, k=min_topic_len)\n",
    "        reviews=reviews.append({\n",
    "            'drugName' : row['DrugName'],\n",
    "            'topic1' : str(random_topics[0]),\n",
    "            'topic2' : str(random_topics[1]),\n",
    "            'topic3' : str(random_topics[2]),\n",
    "            'topic4' : str(random_topics[3]),\n",
    "            'topic5' : str(random_topics[4])},\n",
    "            ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now get the number of reviews that met the criteria*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that the topics have been generated, save a CSV on both local disk as well as Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.to_csv('reviews_50.csv',header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s3_client.upload_file('reviews_50.csv', sagemaker_bucket, reviews_data_prefix+'/reviews_50.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch preparation of drug name/topics\n",
    "\n",
    "Running a large number of calls serially through Amazon Comprehend Medical is, of course, inefficent. Comprehend Medical gives you the ability to batch process millions of notes in a single API call. For a high level overview, see https://aws.amazon.com/blogs/aws/introducing-batch-mode-processing-for-amazon-comprehend-medical/.\n",
    "\n",
    "## N.B. If you run the Comprehend Medical batch calculation across the entire dataset, you may incure charges, and the full analysis will complete after this workshop is complete. Do not do this as part of the workshop. We have provided files for you.\n",
    "\n",
    "Here are the steps to do this for this data set:\n",
    "1. For each line, extract the review and convert it to a JSON file named `<drug_id>.json` with the form `{\"Text\": \"...review...\"}`.\n",
    "2. Upload each of the files to S3 with a shared key space. For example: \n",
    "```\n",
    "lfs401-data/json/112.json\n",
    "lfs401-data/json/3528.json\n",
    "```\n",
    "3. Use Amazon Comprehend Medical Batch Mode to process the files. You can either use the console or the Comprehend Medical API. Save the output to a different key space. The job is submitted asynchronously so you can poll for the job status.\n",
    "4. Once the job is complete, you can access all the files in S3. Pull them back down to your instance to continue.\n",
    "\n",
    "\n",
    "## The post-processing is covered below. Resume with the following cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the output zip file from S3 and get the output path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws s3 cp s3://lfs401-2019reinvent-public-cmh/output.tgz .\n",
    "aws s3 cp s3://lfs401-2019reinvent-public-cmh/source/drugsCom_raw.tsv source/\n",
    "tar xzf output.tgz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = os.getcwd()\n",
    "output_path = os.path.join(mypath,'output', [_ for _ in os.listdir('output') if os.path.isdir(os.path.join('output',_))][0])\n",
    "\n",
    "print ('Comprehend Medical Output Path: %s' % output_path)\n",
    "os.chdir(output_path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check number of files - should be 215063"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -1 | grep -v Manifest | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, iterate through each file. If the file is a valid output name, add it to a dictionary. The file format should look similar to `12345.json.out`, where the numeric value is the id for the entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics_from_file(filename):\n",
    "    with open(filename) as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = dict()\n",
    "counter = 0\n",
    "with os.scandir(output_path) as it:\n",
    "    for entry in it:\n",
    "        if not (entry.name.startswith('.') or entry.name.startswith('Manifest')) and entry.is_file():\n",
    "            d = get_topics_from_file(entry)\n",
    "            id = entry.name.split('.')[0]\n",
    "            \n",
    "            results_dict[id] = d\n",
    "        counter += 1\n",
    "        if counter % 10000 == 0:\n",
    "            print (counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in original files and iterate through to create a list of python dictionaries containing `id`, `drug name`, `condition`, and `review`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'drugsCom_raw.tsv'\n",
    "os.chdir(os.path.join(mypath, 'source'))\n",
    "orig_list = list()\n",
    "\n",
    "with open(filename) as csvfile:\n",
    "    myreader = csv.reader(csvfile, delimiter='\\t')\n",
    "    for row in myreader:\n",
    "        if row[0] == '':\n",
    "            continue\n",
    "        else:\n",
    "            orig_list.append({\n",
    "                'id': row[0],\n",
    "                'drugName': row[1],\n",
    "                'condition': row[2],\n",
    "                'review': row[3]\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirm the length of the dictionary you lozaded in is the same as in the original file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(orig_list) == len(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, create a list for each entry that contains the index, drug name, and list of topics identified by Comprehend Medical. This is effectively an application inner join on index for `orig_list` and `result_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_per_row = list()\n",
    "topic_count = 1\n",
    "\n",
    "for entry in orig_list:\n",
    "    index = entry['id']\n",
    "    drugName = entry['drugName']\n",
    "    v = results_dict[index]\n",
    "\n",
    "    topic_list = []\n",
    "    for entity in v['Entities']:\n",
    "        if entity['Category'] == 'MEDICAL_CONDITION':\n",
    "            topic_list.append(entity['Text'])\n",
    "            topic_count += 1\n",
    "    \n",
    "    topic_dict = dict(\n",
    "        Index=index,\n",
    "        DrugName=drugName,\n",
    "        TopicList=topic_list\n",
    "    )\n",
    "    topics_per_row.append(topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(topics_per_row) == len(orig_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_per_row[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now plot a histogram showing the distribution of number of topics per entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_count = [ len(_['TopicList']) for _ in topics_per_row]\n",
    "plt.hist(topic_count,bins=20,label='Topic Count', range=(0,30))\n",
    "plt.xlabel('Number of topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For this example, we select 5 topics per entry. All entries with fewer than 5 relevant topics identified by Comprehend Medical are discarded. This yields ~80k distinct entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "min_topic_len = 5\n",
    "counter = 0\n",
    "review_list = []\n",
    "\n",
    "for row in topics_per_row:\n",
    "    topic_list = row['TopicList']\n",
    "    if len(topic_list) >= min_topic_len:\n",
    "        # Randomly select topics\n",
    "        random_topics = random.choices(topic_list, k=min_topic_len)\n",
    "        review_list.append({\n",
    "            'drugName' : row['DrugName'],\n",
    "            'topic1' : str(random_topics[0]),\n",
    "            'topic2' : str(random_topics[1]),\n",
    "            'topic3' : str(random_topics[2]),\n",
    "            'topic4' : str(random_topics[3]),\n",
    "            'topic5' : str(random_topics[4])})\n",
    "        \n",
    "reviews = pd.DataFrame(review_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have identified the topics, save the full file, as well as subsamples to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_files_to_disk_and_s3(bucket_name, s3_uri_base, sample_nums, reviews):\n",
    "    for sample_num in sample_nums:\n",
    "        print (sample_num)\n",
    "        path = 'reviews_%ssample.csv' % str(sample_num)\n",
    "        write_file_to_disk_and_s3(bucket_name, s3_uri_base, path, sample_num, reviews)\n",
    "    print ('all reviews')\n",
    "    write_file_to_disk_and_s3(bucket_name, s3_uri_base, 'reviews_all.csv', reviews.shape[0], reviews)\n",
    "\n",
    "def write_file_to_disk_and_s3(bucket_name, s3_uri_base, path, sample_num, reviews):\n",
    "    s3_client = boto3.client('s3')\n",
    "    s3_key = s3_uri_base.rstrip('/') + '/' + path\n",
    "    sampled_reviews = reviews.sample(n=sample_num)\n",
    "    sampled_reviews.to_csv(path, header=True, index=False)\n",
    "    s3_client.upload_file(path, bucket_name, s3_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_numbers = [1000, 2000, 5000, 10000, 20000, 50000]\n",
    "s3_uri_base = 'reviews/'\n",
    "write_files_to_disk_and_s3(sagemaker_bucket, reviews_data_prefix, sample_numbers, reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congrats! You are done with data prep. Move to the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
